{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using question answering pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "nlp = pipeline(\"question-answering\")\n",
    "context = r\"\"\"\n",
    "Extractive Question Answering is the task of extracting an answer from a text given a question. An example of a\n",
    "question answering dataset is the SQuAD dataset, which is entirely based on that task. If you would like to fine-tune\n",
    "a model on a SQuAD task, you may leverage the examples/question-answering/run_squad.py script.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: 'the task of extracting an answer from a text given a question.', score: 0.6226, start: 34, end: 96\n",
      "Answer: 'SQuAD dataset,', score: 0.5053, start: 147, end: 161\n"
     ]
    }
   ],
   "source": [
    "result = nlp(question=\"What is extractive question answering?\", context=context)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")\n",
    "result = nlp(question=\"What is a good example of a question answering dataset?\", context=context)\n",
    "print(f\"Answer: '{result['answer']}', score: {round(result['score'], 4)}, start: {result['start']}, end: {result['end']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a model and a tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\", return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = r\"\"\"\n",
    "ðŸ¤— Transformers (formerly known as pytorch-transformers and pytorch-pretrained-bert) provides general-purpose\n",
    "architectures (BERT, GPT-2, RoBERTa, XLM, DistilBert, XLNetâ€¦) for Natural Language Understanding (NLU) and Natural\n",
    "Language Generation (NLG) with over 32+ pretrained models in 100+ languages and deep interoperability between\n",
    "TensorFlow 2.0 and PyTorch.\n",
    "\"\"\"\n",
    "questions = [\n",
    "    \"How many pretrained models are available in ðŸ¤— Transformers?\",\n",
    "    \"What does ðŸ¤— Transformers provide?\",\n",
    "    \"ðŸ¤— Transformers provides interoperability between which frameworks?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_tokens:  ['[CLS]', 'how', 'many', 'pre', '##train', '##ed', 'models', 'are', 'available', 'in', '[UNK]', 'transformers', '?', '[SEP]', '[UNK]', 'transformers', '(', 'formerly', 'known', 'as', 'p', '##yt', '##or', '##ch', '-', 'transformers', 'and', 'p', '##yt', '##or', '##ch', '-', 'pre', '##train', '##ed', '-', 'bert', ')', 'provides', 'general', '-', 'purpose', 'architecture', '##s', '(', 'bert', ',', 'gp', '##t', '-', '2', ',', 'roberta', ',', 'xl', '##m', ',', 'di', '##sti', '##lbert', ',', 'xl', '##net', 'â€¦', ')', 'for', 'natural', 'language', 'understanding', '(', 'nl', '##u', ')', 'and', 'natural', 'language', 'generation', '(', 'nl', '##g', ')', 'with', 'over', '32', '+', 'pre', '##train', '##ed', 'models', 'in', '100', '+', 'languages', 'and', 'deep', 'inter', '##oper', '##ability', 'between', 'tensor', '##flow', '2', '.', '0', 'and', 'p', '##yt', '##or', '##ch', '.', '[SEP]']\n",
      "answer_start_scores:  tensor([[-6.5990, -6.1387, -7.8761, -7.8292, -8.7167, -8.9216, -8.6420, -8.2637,\n",
      "         -8.1355, -7.8485, -7.9702, -8.3272, -9.3328, -6.5990, -3.5472, -3.5201,\n",
      "         -7.6366, -6.9593, -8.0762, -8.4253, -6.1195, -7.9624, -8.3828, -8.0024,\n",
      "         -8.3195, -5.4944, -8.2405, -6.5540, -8.1549, -8.4309, -8.2269, -8.3963,\n",
      "         -6.7172, -8.1222, -8.3750, -8.2482, -5.6149, -6.8511, -6.3145, -6.1016,\n",
      "         -7.6912, -7.6393, -5.7812, -7.5353, -7.2942, -5.4125, -8.2601, -6.2903,\n",
      "         -8.0463, -8.2036, -7.1411, -8.3341, -6.6303, -8.4391, -6.5964, -7.9467,\n",
      "         -8.5371, -7.0665, -8.0596, -7.9908, -8.5030, -7.0008, -7.7140, -6.2754,\n",
      "         -6.6136, -7.0534, -5.5944, -6.5917, -6.9854, -8.0204, -6.4408, -7.9721,\n",
      "         -7.5704, -8.2496, -5.2606, -6.5214, -6.1437, -7.8759, -5.9586, -7.1834,\n",
      "         -5.0404, -2.2078,  5.1718,  4.9945, -3.1125, -4.7365, -6.2348, -6.1286,\n",
      "         -3.5514, -5.0355, -1.5301, -6.8052, -5.3237, -7.6279, -6.0547, -6.7887,\n",
      "         -7.3029, -7.1165, -8.4357, -6.7688, -8.4068, -8.0120, -9.0702, -8.1692,\n",
      "         -8.8216, -7.1791, -8.5596, -8.5240, -7.6562, -7.9499, -6.5990]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "answer_end_scores:  tensor([[-2.5594, -6.4247, -5.8280, -6.4433, -6.1979, -5.9784, -5.1702, -6.6323,\n",
      "         -6.7585, -6.7245, -5.8998, -5.3061, -6.3955, -2.5593, -2.4550, -1.7282,\n",
      "         -5.7270, -6.3138, -5.9894, -6.5808, -6.4406, -5.9453, -6.3294, -5.3017,\n",
      "         -6.8951, -3.8077, -6.5927, -7.0449, -6.4237, -6.7989, -5.8293, -6.8708,\n",
      "         -7.0504, -6.3133, -5.7162, -6.8942, -4.0946, -4.5682, -5.9985, -6.3764,\n",
      "         -5.9618, -6.0688, -4.6115, -4.5058, -7.0244, -4.9782, -5.5396, -6.6817,\n",
      "         -5.7140, -6.7167, -4.1738, -4.9484, -5.5196, -4.8330, -6.8047, -5.0584,\n",
      "         -4.9405, -6.7266, -6.5254, -5.5140, -4.7950, -6.8246, -4.0207, -3.8135,\n",
      "         -4.5401, -6.6328, -5.7372, -4.6938, -4.4819, -6.9273, -6.5843, -5.7663,\n",
      "         -4.9241, -7.2208, -6.0085, -5.1859, -4.5740, -6.7747, -6.6924, -5.3053,\n",
      "         -4.4400, -6.1836, -1.2650,  5.2873,  5.9761, -1.7422, -1.3852,  0.7164,\n",
      "          4.1504, -4.9742, -1.8202, -1.8320,  0.4979, -2.7480, -6.2393, -5.8049,\n",
      "         -5.3029, -3.3956, -6.0481, -6.4066, -4.9983, -5.9262, -6.7127, -4.6627,\n",
      "         -6.9819, -6.8900, -6.4833, -6.8604, -3.9858, -3.5833, -2.5595]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "start_max:  tensor(5.1718, grad_fn=<MaxBackward1>)  start_argmax:  tensor(82)\n",
      "end_max:  tensor(5.9761, grad_fn=<MaxBackward1>)  end_argmax:  tensor(84)\n",
      "Question: How many pretrained models are available in ðŸ¤— Transformers?\n",
      "Answer(82,85): over 32 +\n",
      "text_tokens:  ['[CLS]', 'what', 'does', '[UNK]', 'transformers', 'provide', '?', '[SEP]', '[UNK]', 'transformers', '(', 'formerly', 'known', 'as', 'p', '##yt', '##or', '##ch', '-', 'transformers', 'and', 'p', '##yt', '##or', '##ch', '-', 'pre', '##train', '##ed', '-', 'bert', ')', 'provides', 'general', '-', 'purpose', 'architecture', '##s', '(', 'bert', ',', 'gp', '##t', '-', '2', ',', 'roberta', ',', 'xl', '##m', ',', 'di', '##sti', '##lbert', ',', 'xl', '##net', 'â€¦', ')', 'for', 'natural', 'language', 'understanding', '(', 'nl', '##u', ')', 'and', 'natural', 'language', 'generation', '(', 'nl', '##g', ')', 'with', 'over', '32', '+', 'pre', '##train', '##ed', 'models', 'in', '100', '+', 'languages', 'and', 'deep', 'inter', '##oper', '##ability', 'between', 'tensor', '##flow', '2', '.', '0', 'and', 'p', '##yt', '##or', '##ch', '.', '[SEP]']\n",
      "answer_start_scores:  tensor([[-6.5568, -7.2897, -8.5465, -8.5011, -8.3476, -8.2413, -9.6900, -6.5568,\n",
      "         -3.5090, -2.6047, -6.3426, -6.0519, -7.8244, -8.0512, -4.3812, -7.7132,\n",
      "         -8.0174, -8.0607, -8.4374, -5.3181, -8.0256, -3.7490, -7.2895, -7.6626,\n",
      "         -7.3129, -7.7497, -4.0316, -7.4047, -8.1795, -7.6586, -3.2422, -1.5652,\n",
      "          3.4253,  6.4664, -3.1268, -0.3745,  1.0288, -2.6647, -2.7628, -2.2377,\n",
      "         -7.4948, -4.5590, -8.0461, -8.3301, -7.2158, -8.4032, -5.0446, -8.3850,\n",
      "         -4.7716, -7.5270, -8.6528, -5.8540, -7.8777, -7.7526, -8.3915, -4.3607,\n",
      "         -5.9761, -6.0694, -3.8772, -0.4859,  2.0066, -3.0643, -3.5487, -3.6057,\n",
      "         -3.2810, -6.3222, -5.3194, -5.1330,  0.5841, -4.3058, -3.9413, -4.8750,\n",
      "         -3.7340, -6.0566, -4.5063, -2.9494, -1.2663, -4.6832, -7.3241, -2.3922,\n",
      "         -6.6961, -7.4455, -4.3266, -6.2002, -4.8033, -7.9482, -3.8558, -6.6334,\n",
      "         -0.5083, -3.8520, -6.3841, -5.8912, -6.9113, -5.3207, -7.8832, -8.1903,\n",
      "         -9.3457, -8.0536, -9.0324, -6.2872, -8.1557, -8.3160, -6.6943, -7.1408,\n",
      "         -6.5569]], grad_fn=<SqueezeBackward1>)\n",
      "answer_end_scores:  tensor([[-1.3792, -6.4264, -7.2481, -6.7315, -7.3681, -7.8096, -7.9964, -1.3791,\n",
      "         -4.1006, -3.9893, -6.5061, -7.3050, -6.8607, -6.9850, -6.6130, -6.5702,\n",
      "         -7.0070, -5.9095, -7.0276, -3.8996, -7.0567, -6.8201, -6.4662, -7.1276,\n",
      "         -6.1553, -7.4590, -6.3654, -6.8156, -5.7610, -6.8288, -2.1095, -3.7463,\n",
      "         -3.1759, -2.4358, -4.7304, -2.0633, -0.6370,  6.2707, -4.0150, -1.0263,\n",
      "         -3.8900, -5.8681, -5.0560, -6.3045, -2.1081, -4.5499, -3.3340, -4.6427,\n",
      "         -5.9300, -3.6771, -4.6659, -6.0570, -6.0965, -3.1805, -4.4157, -5.5628,\n",
      "         -0.1343, -1.4478,  2.6846, -2.0287, -2.9236, -1.9182,  4.0120, -5.2031,\n",
      "         -4.1959, -0.1573,  2.8401, -3.9490, -3.5110, -2.0142,  3.5856, -4.5569,\n",
      "         -4.3347,  0.7176,  4.8402, -3.4391, -5.4805, -4.8703, -5.6010, -4.9486,\n",
      "         -5.0761, -3.4984,  1.2719, -6.0745, -4.9132, -5.4301,  1.0250, -4.3932,\n",
      "         -4.9151, -4.8211, -5.2505,  0.4006, -4.0765, -5.7212, -3.1642, -4.8162,\n",
      "         -6.5389, -2.1956, -6.4645, -5.8529, -6.1346, -5.9048,  1.3448,  0.2200,\n",
      "         -1.3796]], grad_fn=<SqueezeBackward1>)\n",
      "start_max:  tensor(6.4664, grad_fn=<MaxBackward1>)  start_argmax:  tensor(33)\n",
      "end_max:  tensor(6.2707, grad_fn=<MaxBackward1>)  end_argmax:  tensor(37)\n",
      "Question: What does ðŸ¤— Transformers provide?\n",
      "Answer(33,38): general - purpose architectures\n",
      "text_tokens:  ['[CLS]', '[UNK]', 'transformers', 'provides', 'inter', '##oper', '##ability', 'between', 'which', 'framework', '##s', '?', '[SEP]', '[UNK]', 'transformers', '(', 'formerly', 'known', 'as', 'p', '##yt', '##or', '##ch', '-', 'transformers', 'and', 'p', '##yt', '##or', '##ch', '-', 'pre', '##train', '##ed', '-', 'bert', ')', 'provides', 'general', '-', 'purpose', 'architecture', '##s', '(', 'bert', ',', 'gp', '##t', '-', '2', ',', 'roberta', ',', 'xl', '##m', ',', 'di', '##sti', '##lbert', ',', 'xl', '##net', 'â€¦', ')', 'for', 'natural', 'language', 'understanding', '(', 'nl', '##u', ')', 'and', 'natural', 'language', 'generation', '(', 'nl', '##g', ')', 'with', 'over', '32', '+', 'pre', '##train', '##ed', 'models', 'in', '100', '+', 'languages', 'and', 'deep', 'inter', '##oper', '##ability', 'between', 'tensor', '##flow', '2', '.', '0', 'and', 'p', '##yt', '##or', '##ch', '.', '[SEP]']\n",
      "answer_start_scores:  tensor([[-6.1479, -8.1504, -8.0547, -8.2172, -8.2597, -9.0340, -9.1834, -8.5189,\n",
      "         -7.0241, -8.2608, -8.8719, -9.7697, -6.1478, -5.6884, -3.5799, -7.2198,\n",
      "         -5.8089, -7.5308, -7.7310, -0.2308, -6.2658, -6.5939, -5.9501, -7.4640,\n",
      "         -4.6919, -6.0423, -0.7622, -6.1282, -6.7993, -6.0876, -6.4823, -3.8885,\n",
      "         -7.2929, -7.8001, -6.8442, -2.1224, -6.9784, -3.6053, -0.7250, -7.1122,\n",
      "         -4.8897, -3.4082, -5.9891, -1.8026,  2.1470, -5.6282, -1.4007, -6.5709,\n",
      "         -7.2383, -5.8166, -7.8012, -4.1402, -7.5582, -4.1243, -6.8240, -8.0695,\n",
      "         -4.9950, -7.3042, -6.9205, -8.0321, -5.2739, -6.0296, -6.3443, -6.4113,\n",
      "         -3.2012,  1.8201, -4.3072, -5.1026, -2.3548, -0.6008, -6.1212, -6.4907,\n",
      "         -6.0279, -2.2168, -6.1134, -5.6783, -5.4636, -5.1583, -6.1090, -5.3320,\n",
      "         -6.8291, -6.3435, -7.2655, -8.5996, -6.2427, -8.2107, -8.5213, -5.5052,\n",
      "         -7.9098, -6.9709, -8.8957, -5.3920, -6.2110, -1.8061, -3.2943, -5.5694,\n",
      "         -5.5466, -0.2703,  6.1828, -1.8695, -1.4110, -4.2710, -3.9795, -3.7275,\n",
      "         -1.1113, -4.8465, -5.6759, -3.7093, -4.5269, -6.1481]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "answer_end_scores:  tensor([[-1.7815, -6.9374, -7.7163, -8.5723, -8.4385, -8.1414, -7.8872, -7.9860,\n",
      "         -6.9736, -7.4682, -7.5531, -7.9218, -1.7815, -5.1120, -3.1626, -6.5966,\n",
      "         -7.4106, -7.1401, -7.2214, -4.9722, -5.6500, -5.9744, -1.9263, -6.4549,\n",
      "         -2.3331, -6.4600, -5.0318, -5.5210, -5.6765, -1.5703, -6.4762, -6.1248,\n",
      "         -6.1384, -4.6934, -6.0532,  0.6827, -4.9500, -6.9684, -5.4231, -7.3902,\n",
      "         -4.4849, -3.2898, -1.3844, -6.2171, -3.2169, -4.0713, -4.8511, -4.4141,\n",
      "         -5.8629, -0.6848, -2.3607, -1.6261, -2.8482, -5.2227, -2.4681, -3.0868,\n",
      "         -4.7647, -5.7693, -1.8203, -3.3359, -4.9315,  0.4738, -0.9116, -2.2153,\n",
      "         -5.6263, -3.6996, -3.6447, -1.9957, -6.2649, -4.6642, -3.5041, -2.6142,\n",
      "         -5.3556, -4.3893, -3.5511,  0.2041, -6.0318, -5.0779, -0.3175,  2.2365,\n",
      "         -3.2694, -6.3493, -6.1205, -6.4001, -6.5812, -6.4828, -5.6410, -2.9006,\n",
      "         -6.9492, -6.4215, -6.3765, -2.4754, -5.6369, -4.7798, -6.6399, -6.3422,\n",
      "         -4.2503, -4.7065, -2.5913, -0.7375, -3.0312, -4.1550, -0.5356, -2.6972,\n",
      "         -1.7214, -2.4599, -2.9641,  6.5932,  5.1990, -1.7821]],\n",
      "       grad_fn=<SqueezeBackward1>)\n",
      "start_max:  tensor(6.1828, grad_fn=<MaxBackward1>)  start_argmax:  tensor(98)\n",
      "end_max:  tensor(6.5932, grad_fn=<MaxBackward1>)  end_argmax:  tensor(107)\n",
      "Question: ðŸ¤— Transformers provides interoperability between which frameworks?\n",
      "Answer(98,108): tensorflow 2 . 0 and pytorch\n"
     ]
    }
   ],
   "source": [
    "for question in questions:\n",
    "    inputs = tokenizer(question, text, add_special_tokens=True, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "    \n",
    "    text_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    print(\"text_tokens: \", text_tokens)\n",
    "    \n",
    "    #answer_start_scores, answer_end_scores = model(**inputs)\n",
    "    outputs = model(**inputs)\n",
    "    answer_start_scores = outputs[0]\n",
    "    print(\"answer_start_scores: \", answer_start_scores)\n",
    "    \n",
    "    answer_end_scores = outputs[1]\n",
    "    print(\"answer_end_scores: \", answer_end_scores)\n",
    "    \n",
    "    answer_start = torch.argmax(answer_start_scores)  # Get the most likely beginning of answer with the argmax of the score\n",
    "    print(\"start_max: \", torch.max(answer_start_scores), \" start_argmax: \", torch.argmax(answer_start_scores))\n",
    "    \n",
    "    answer_end = torch.argmax(answer_end_scores) + 1  # Get the most likely end of answer with the argmax of the score\n",
    "    print(\"end_max: \", torch.max(answer_end_scores), \" end_argmax: \", torch.argmax(answer_end_scores))\n",
    "    \n",
    "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
    "    \n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Answer({answer_start},{answer_end}): {answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
